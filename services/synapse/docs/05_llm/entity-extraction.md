# LLM 기반 개체명 인식 상세

## 이 문서가 답하는 질문

- 비즈니스 프로세스 도메인의 NER에서 어떤 개체 유형을 추출하는가?
- 각 개체 유형별 추출 전략과 정규화 규칙은?
- 한국어 비즈니스 문서 NER의 특수한 어려움과 해결책은?
- NER 품질을 어떻게 평가하는가?

<!-- affects: backend -->
<!-- requires-update: 03_backend/ner-extractor.md -->

---

## 1. 추출 대상 개체 유형 상세

### 1.1 COMPANY (회사/법인)

| 항목 | 설명 |
|------|------|
| **정의** | 법인, 회사, 기관 명칭 |
| **예시** | "XYZ 주식회사", "ABC 제조(주)", "국민은행" |
| **정규화** | 정식 법인명으로 통일 (주->주식회사, (주)->주식회사) |
| **난이도** | 중 (약어, 계열사 구분 필요) |

**특수 처리**:
- "대상 조직", "의뢰인" -> COMPANY가 아닌 역할 참조. 문맥에서 실제 회사명 매칭 필요
- "거래처", "협력사" -> 비즈니스 맥락에서 회사명 해결 필요

### 1.2 PERSON (인물)

| 항목 | 설명 |
|------|------|
| **정의** | 프로젝트 관계자 인명 |
| **예시** | "홍길동", "분석가 김모", "매니저 이영희" |
| **정규화** | 이름만 추출, 직함은 메타데이터로 분리 |
| **난이도** | 상 (익명 처리 "김모", 직함+이름 결합) |

**특수 처리**:
- "김모": 익명화된 이름, confidence 하향 (0.5-0.7)
- "분석가": 역할이지 이름이 아님, 뒤따르는 이름과 분리

### 1.3 AMOUNT (금액)

| 항목 | 설명 |
|------|------|
| **정의** | 화폐 금액 |
| **예시** | "100억원", "5,000,000,000원", "USD 1,000,000" |
| **정규화** | 정수 문자열 (예: "10000000000") |
| **난이도** | 중 (한국어 단위 변환) |

**정규화 규칙**:

```
"100억원"        -> "10000000000"
"50만원"         -> "500000"
"3조 5천억원"    -> "3500000000000"
"약 80억원"      -> "8000000000" (confidence 하향)
"금 100,000,000원" -> "100000000"
```

### 1.4 DATE (일자)

| 항목 | 설명 |
|------|------|
| **정의** | 날짜, 기간 |
| **예시** | "2024년 1월 15일", "2024.01.15", "작년 3월" |
| **정규화** | ISO 8601 (예: "2024-01-15") |
| **난이도** | 중 (상대 날짜 해석 필요) |

**정규화 규칙**:

```
"2024년 1월 15일"  -> "2024-01-15"
"2024.1.15"        -> "2024-01-15"
"작년 3월"         -> "2023-03-01" (confidence 0.6, 정확 일자 불명)
"위 시작일로부터 1개월 이내" -> null (기간, HITL 필요)
```

### 1.5 PROCESS_STEP (비즈니스 프로세스 단계)

| 항목 | 설명 |
|------|------|
| **정의** | 비즈니스 프로세스 단계 명칭 |
| **예시** | "데이터 수집", "프로세스 분석", "최적화 실행", "성과 검토" |
| **정규화** | 표준 프로세스명 (DataCollection, ProcessAnalysis 등) |
| **난이도** | 중 (유사 용어 구분) |

**프로세스명 표준화**:

| 원문 표현 | 정규화 | 온톨로지 매핑 |
|----------|--------|-------------|
| 데이터 수집, 정보 수집 | DataCollection | Process |
| 프로세스 분석, 현황 분석 | ProcessAnalysis | Process |
| 최적화, 개선 | Optimization | Process |
| 실행, 구현 | Execution | Process |
| 검토, 성과 평가 | Review | Process |
| 모니터링, 감시 | Monitoring | Process |

### 1.6 METRIC (비즈니스 지표)

| 항목 | 설명 |
|------|------|
| **정의** | 비즈니스 지표 유형과 금액 |
| **예시** | "매출 500억원", "영업이익률 15%", "생산 처리량 1,000건/일" |
| **정규화** | 유형 + 금액 분리 |
| **난이도** | 상 (유형 분류 + 금액 추출 복합) |

### 1.7 기타 유형

| 유형 | 정의 | 난이도 |
|------|------|--------|
| DEPARTMENT | 부서/팀명 | 하 (패턴 명확) |
| ASSET_TYPE | 자산 유형 | 중 |
| CONTRACT | 계약 유형 | 중 |
| FINANCIAL_METRIC | 재무 지표 | 중 |
| REFERENCE | 규정/법령 참조 | 하 (패턴 명확) |

---

## 2. 한국어 비즈니스 문서 NER 난점

### 2.1 문제와 해결

| 난점 | 예시 | 해결 방법 |
|------|------|----------|
| **교착어 조사 처리** | "XYZ 주식회사의", "기획팀에" | 조사 제거 정규화 |
| **익명화 표현** | "김모", "A 회사", "해당 업체" | confidence 하향 + HITL |
| **복합 금액 표현** | "금 100억원(정)", "약 80억원 상당" | 단위 파서 + 수식어 무시 |
| **상대적 날짜** | "위 시작일로부터 7일 이내" | 기준 일자 참조 필요, HITL |
| **동일 개체 다른 표현** | "대상 조직", "의뢰인", "XYZ 주식회사" | 코레퍼런스 해결 (2단계) |
| **비즈니스 전문 용어** | "EBITDA", "ROI", "스루풋" | 도메인 용어 사전 내장 |

### 2.2 코레퍼런스 해결 (Coreference Resolution)

```python
async def resolve_coreferences(
    self, entities: list[dict], text: str
) -> list[dict]:
    """
    Resolve coreferences: merge entities that refer to the same real-world entity.

    Example:
      "대상 조직" + "XYZ 주식회사" + "의뢰인" -> single entity "XYZ 주식회사"
    """
    prompt = f"""
    다음 개체 목록에서 동일한 실체를 가리키는 개체들을 묶으세요.
    예: "대상 조직", "XYZ 주식회사", "의뢰인"이 모두 같은 회사면 하나로 통합합니다.

    개체 목록:
    {json.dumps(entities, ensure_ascii=False)}

    원문:
    {text}
    """
    # Use Structured Output to get merged entity groups
    ...
```

---

## 3. NER 품질 평가

### 3.1 평가 지표

| 지표 | 정의 | 목표 |
|------|------|------|
| Precision | 추출된 개체 중 정확한 비율 | > 0.85 |
| Recall | 실제 개체 중 추출된 비율 | > 0.80 |
| F1-Score | Precision과 Recall의 조화평균 | > 0.82 |
| Type Accuracy | 개체 유형 분류 정확도 | > 0.90 |
| Normalization Accuracy | 정규화 정확도 | > 0.88 |

### 3.2 평가 데이터셋 구축

- 실제 비즈니스 문서 10건 이상을 수동 라벨링
- 개체 유형별 최소 50개 샘플
- 정기적 재평가 (프롬프트 변경 시)

### 3.3 자동 평가 파이프라인

```python
async def evaluate_ner(self, test_dataset: list[dict]) -> dict:
    """
    Evaluate NER against gold-standard labeled data.

    Args:
        test_dataset: List of {"text": str, "gold_entities": list}

    Returns:
        {"precision": float, "recall": float, "f1": float, "by_type": dict}
    """
    ...
```

---

## 금지 규칙

- 원문에 없는 개체를 추측하여 추출하지 않는다
- 신뢰도 점수를 일괄 1.0으로 설정하지 않는다
- 코레퍼런스 해결 시 확실하지 않은 병합을 하지 않는다

## 필수 규칙

- 모든 금액은 정수 문자열로 정규화한다
- 모든 일자는 ISO 8601로 정규화한다
- 익명화된 인물명은 confidence를 0.5-0.7로 제한한다
- 추출 결과에 원문 context를 항상 포함한다

---

## 근거 문서

- `05_llm/structured-output.md` (Structured Output 설정)
- `03_backend/ner-extractor.md` (NER 엔진 구현)
- ADR-003: GPT-4o Structured Output 선택
