# ADR-005: 캐시 품질 게이트 (N회 LLM 심사)

## 상태

Accepted

## 배경

NL2SQL 파이프라인의 결과(질문-SQL 쌍)를 Synapse 백엔드 그래프 저장소에 캐싱하면 유사 질문의 정확도가 향상되고 LLM 호출 비용이 절감된다. 그러나 **잘못된 SQL을 캐싱하면 오히려 향후 유사 질문의 정확도가 하락**한다.

이 "거짓 캐시" 문제를 해결하기 위한 품질 검증 전략을 선택해야 한다:

1. **무조건 캐싱**: 모든 결과를 캐싱
2. **N회 LLM 심사 (품질 게이트)**: LLM이 N회 독립 심사하여 임계값 이상만 캐싱
3. **사용자 피드백 기반**: 사용자가 "좋아요" 누른 것만 캐싱
4. **실행 결과 기반**: SQL 실행 성공/실패로만 판단

## 고려한 옵션

### 옵션 A: 무조건 캐싱

**장점**: 구현 단순, 모든 결과 활용
**단점**: 잘못된 SQL이 캐싱되어 오답 전파. "쓰레기가 들어가면 쓰레기가 나온다"

### 옵션 B: N회 LLM 심사 (품질 게이트)

**장점**:
- 자동화된 품질 검증
- N회 독립 심사로 단일 판단의 편향 완화
- 신뢰도(confidence)를 수치화하여 캐시 품질 추적 가능
- K-AIR에서 검증된 방식

**단점**:
- LLM 호출 비용 (심사 N회 추가)
- 심사 자체의 정확도가 100%가 아님 (LLM의 한계)
- 백그라운드 처리 필요 (사용자 응답 후)

### 옵션 C: 사용자 피드백 기반

**장점**: 인간 판단이 가장 정확
**단점**:
- 피드백 비율이 낮음 (대부분의 사용자는 피드백 안 함)
- 캐시 축적 속도가 매우 느림
- 초기 단계에서 캐시가 비어 있음

### 옵션 D: 실행 결과 기반

**장점**: 단순, 추가 비용 없음
**단점**: SQL이 "실행"은 되지만 "정확하지 않은" 경우를 감지 못함
- 예: "매출 현황"에 대해 `SELECT COUNT(*) FROM departments`가 실행은 성공하지만 의미적으로 오답

## 선택한 결정

**옵션 B: N회 LLM 심사 (품질 게이트)**

### 설정값

| 설정 | 값 | 근거 |
|------|-----|------|
| `judge_rounds` | 2 | 비용과 정확도의 균형 |
| `conf_threshold` | 0.90 | 거짓 캐시의 피해가 캐시 미스보다 큼 |

## 근거

1. **거짓 캐시의 비대칭적 피해**: 잘못된 SQL이 캐싱되면 유사한 모든 향후 질문이 오답을 반환한다. 반면 캐시 미스는 LLM이 새로 생성하면 되므로 피해가 적다. 따라서 **높은 임계값(0.90)**이 정당화된다.

2. **N회 독립 심사의 강건성**: 단일 LLM 판단은 temperature와 맥락에 따라 변동한다. 2회 독립 심사(서로 다른 temperature)로 이 변동을 완화하여 판단 안정성을 높인다.

3. **비용 분석**:
   - 심사 1회: ~$0.005 (gpt-4o, ~1000 토큰)
   - 심사 2회: ~$0.01/요청
   - 월간 1,000 요청 기준: ~$10/월
   - 이 비용으로 캐시 품질을 보장하면 장기적으로 LLM 호출 비용 절감 (캐시 히트 시 SQL 생성 비용 $0)

4. **백그라운드 처리**: 심사는 사용자 응답 후 백그라운드에서 실행되므로 사용자 경험에 영향 없음.

5. **K-AIR 검증**: `cache_postprocess.py`에서 이 패턴이 구현되어 안정적으로 동작 중.

## 결과

### 긍정적 영향

- 캐시 품질 보장 (거짓 캐시 최소화)
- 시간이 지날수록 캐시 정확도 향상
- confidence 기반 캐시 우선순위 지원

### 부정적 영향

- 심사 비용 (요청당 ~$0.01)
- 심사 자체의 오판 가능성 (LLM은 완벽하지 않음)
- 높은 임계값(0.90)으로 인해 캐시 축적 속도가 느릴 수 있음

### 완화 전략

- **비용**: gpt-4o-mini 사용 검토 (심사 비용 1/10)
- **오판**: 사용자 피드백과 조합 (피드백으로 confidence 보정)
- **축적 속도**: PENDING 상태(0.80~0.90) 쿼리를 추가 심사하여 점진적 승인

## N회 심사 세부 설계

### 심사 프로세스

```
┌────────────────────────────────────────────────────────┐
│  Quality Gate Process                                   │
│                                                          │
│  Round 1 (temperature=0.3):                             │
│  ┌──────────┐                                           │
│  │ LLM 심사 │ → {accuracy:0.92, reasonableness:0.88,    │
│  │ (보수적)  │    quality:0.90, overall:0.90}            │
│  └──────────┘                                           │
│                                                          │
│  Round 2 (temperature=0.5):                             │
│  ┌──────────┐                                           │
│  │ LLM 심사 │ → {accuracy:0.95, reasonableness:0.92,    │
│  │ (중립적)  │    quality:0.88, overall:0.92}            │
│  └──────────┘                                           │
│                                                          │
│  평균 overall = (0.90 + 0.92) / 2 = 0.91               │
│  0.91 >= 0.90 (threshold) → APPROVE                    │
│                                                          │
│  → Synapse 백엔드 Query 노드 생성 (confidence=0.91)    │
└────────────────────────────────────────────────────────┘
```

### 3단계 결정

| 조건 | 결정 | 후속 처리 |
|------|------|----------|
| 평균 >= 0.90 | APPROVE | Synapse 백엔드 그래프에 영속화 |
| 0.80 <= 평균 < 0.90 | PENDING | 추가 심사 대기열에 저장 |
| 평균 < 0.80 | REJECT | 캐싱하지 않음, 로그만 기록 |

## 재평가 조건

- 캐시 축적 속도가 너무 느릴 때 (임계값 조정 검토)
- 심사 비용이 예산을 초과할 때 (횟수 또는 모델 조정)
- 사용자 피드백 기반 캐싱이 충분한 정확도를 보일 때
- 거짓 캐시 비율이 높다는 데이터가 있을 때 (임계값 상향 검토)

---

**근거 문서**: [03_backend/cache-system.md](../03_backend/cache-system.md)
**영향 문서**: [06_data/neo4j-schema.md](../06_data/neo4j-schema.md), [05_llm/llm-factory.md](../05_llm/llm-factory.md)
